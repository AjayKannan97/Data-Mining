{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from math import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read cgm inputs\n",
    "def read_cgm(fname):\n",
    "    df_cgm_col = ['Index','Date','Time','Sensor Glucose (mg/dL)']\n",
    "    df_cgm = pd.read_csv(fname,sep=',', usecols=df_cgm_col)\n",
    "    df_cgm['TimeStamp'] = pd.to_datetime(df_cgm['Date'] + ' ' + df_cgm['Time'])\n",
    "    df_cgm['CGM'] = df_cgm['Sensor Glucose (mg/dL)']\n",
    "    df_cgm = df_cgm[['Index','TimeStamp','CGM','Date','Time']]\n",
    "    df_cgm = df_cgm.sort_values(by=['TimeStamp'], ascending=True).fillna(method='ffill')\n",
    "    df_cgm = df_cgm.drop(columns=['Date', 'Time','Index']).sort_values(by=['TimeStamp'], ascending=True)\n",
    "    #print(df_cgm)\n",
    "\n",
    "    df_cgm = df_cgm[df_cgm['CGM'].notna()]\n",
    "\n",
    "    df_cgm.reset_index(drop=True, inplace=True)\n",
    "    #print(len(df_cgm))\n",
    "    return df_cgm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Insulin inputs\n",
    "def read_insluin(fname):\n",
    "    df_ins = pd.read_csv(fname, dtype='unicode')\n",
    "    df_ins['DateTime'] = pd.to_datetime(df_ins['Date'] + \" \" + df_ins['Time'])\n",
    "    df_ins = df_ins[[\"Date\", \"Time\", \"DateTime\", \"BWZ Carb Input (grams)\"]]\n",
    "    df_ins['ins'] = df_ins['BWZ Carb Input (grams)'].astype(float)\n",
    "    df_ins = df_ins[(df_ins.ins != 0)]\n",
    "    df_ins = df_ins[df_ins['ins'].notna()]\n",
    "    df_ins = df_ins.drop(columns=['Date', 'Time','BWZ Carb Input (grams)']).sort_values(by=['DateTime'], ascending=True)\n",
    "    df_ins.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_ins_shift = df_ins.shift(-1)\n",
    "    df_ins = df_ins.join(df_ins_shift.rename(columns=lambda x: x+\"_lag\"))\n",
    "    df_ins['tot_mins_diff'] = (df_ins.DateTime_lag - df_ins.DateTime) / pd.Timedelta(minutes=1)\n",
    "    df_ins['Patient'] = 'P1'\n",
    "\n",
    "    df_ins.drop(df_ins[df_ins['tot_mins_diff'] < 120].index, inplace = True)\n",
    "    df_ins = df_ins[df_ins['ins_lag'].notna()]\n",
    "    #print(df_ins)\n",
    "\n",
    "    return df_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_bins(df_ins):\n",
    "    df_bins = df_ins['ins']\n",
    "    #print(\"insulin lenght\" , len(df_bins))\n",
    "    max_val = df_bins.max()\n",
    "    min_val = df_bins.min()\n",
    "    bins = int((max_val - min_val)/20)\n",
    "\n",
    "    bin_label = []\n",
    "    for x in range(0,bins+1):\n",
    "        bin_label.append(int(min_val + x*20))\n",
    "\n",
    "\n",
    "    return bin_label,bins, min_val, max_val\n",
    "\n",
    "def cal_gt(df_ins,x1_len):\n",
    "    bin_label, bins, min_val, max_val = cal_bins(df_ins)\n",
    "    df_ins['min_val'] = min_val\n",
    "    df_ins['bins'] = ((df_ins['ins'] - df_ins['min_val'])/20).apply(np.ceil)\n",
    "\n",
    "    bin_truth = pd.concat([x1_len, df_ins], axis=1)\n",
    "    bin_truth = bin_truth[bin_truth['len'].notna()]\n",
    "\n",
    "    bin_truth.drop(bin_truth[bin_truth['len'] < 30].index, inplace=True)\n",
    "    df_ins.reset_index(drop=True, inplace=True)\n",
    "    #print(bin_truth)\n",
    "\n",
    "    return bin_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_meal_time(df_ins,df_cgm):\n",
    "    ### calculate meal/nomeal times ######\n",
    "    df_mtime = []\n",
    "    for x in df_ins.index:\n",
    "        df_mtime.append([df_ins['DateTime'][x] + pd.DateOffset(hours=-0.5),\n",
    "                         df_ins['DateTime'][x] + pd.DateOffset(hours=+2)])\n",
    "\n",
    "    df_m = []\n",
    "    for x in range(len(df_mtime)):\n",
    "        data = df_cgm.loc[(df_cgm['TimeStamp'] >= df_mtime[x][0]) & (df_cgm['TimeStamp'] < df_mtime[x][1])]['CGM']\n",
    "        df_m.append(data)\n",
    "\n",
    "    df_ml_length = []\n",
    "    df_mf = []\n",
    "    y = 0\n",
    "    for x in df_m:\n",
    "        y = len(x)\n",
    "        df_ml_length.append(y)\n",
    "        if len(x) == 30:\n",
    "            df_mf.append(x)\n",
    "\n",
    "    df_length = DataFrame(df_ml_length, columns=['len'])\n",
    "    df_length.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_mf, df_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins(result_labels, true_label):\n",
    "    #print(result_labels)\n",
    "    #for x in range(len(result_labels)):\n",
    "    #    print(result_labels[x])\n",
    "    bin_result = {}\n",
    "    bin_result[1] = []\n",
    "    bin_result[2] = []\n",
    "    bin_result[3] = []\n",
    "    bin_result[4] = []\n",
    "    bin_result[5] = []\n",
    "    bin_result[6] = []\n",
    "    for i in range(len(result_labels)):\n",
    "        if result_labels[i] == 0:\n",
    "            bin_result[1].append(i)\n",
    "        elif result_labels[i] == 1:\n",
    "            bin_result[2].append(i)\n",
    "        elif result_labels[i] == 2:\n",
    "            bin_result[3].append(i)\n",
    "        elif result_labels[i] == 3:\n",
    "            bin_result[4].append(i)\n",
    "        elif result_labels[i] == 4:\n",
    "            bin_result[5].append(i)\n",
    "        elif result_labels[i] == 5:\n",
    "            bin_result[6].append(i)\n",
    "\n",
    "    bin_1 = []\n",
    "    bin_2 = []\n",
    "    bin_3 = []\n",
    "    bin_4 = []\n",
    "    bin_5 = []\n",
    "    bin_6 = []\n",
    "\n",
    "    for i in bin_result[1]:\n",
    "        bin_1.append(true_label[i])\n",
    "    for i in bin_result[2]:\n",
    "        bin_2.append(true_label[i])\n",
    "    for i in bin_result[2]:\n",
    "        bin_3.append(true_label[i])\n",
    "    for i in bin_result[4]:\n",
    "        bin_4.append(true_label[i])\n",
    "    for i in bin_result[5]:\n",
    "        bin_5.append(true_label[i])\n",
    "    for i in bin_result[6]:\n",
    "        bin_6.append(true_label[i])\n",
    "    total = len(bin_1) + len(bin_2) + len(bin_3) + len(bin_4) + len(bin_5) + len(bin_6)\n",
    "\n",
    "    return total, bin_1, bin_2, bin_3, bin_4, bin_5, bin_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSSE(bin):\n",
    "    if len(bin) != 0:\n",
    "        SSE = 0\n",
    "        avg = sum(bin) / len(bin)\n",
    "        for i in bin:\n",
    "            SSE += (i - avg) * (i - avg)\n",
    "        return SSE\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateSSE(bin):\n",
    "    if len(bin) != 0:\n",
    "        SSE = 0\n",
    "        avg = sum(bin) / len(bin)\n",
    "        for i in bin:\n",
    "            SSE += (i - avg) * (i - avg)\n",
    "        return SSE\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wingman2.0/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cgm = read_cgm('./CGMData.csv')\n",
    "df_insulin = read_insluin('./InsulinData.csv')\n",
    "\n",
    "x1, x1_len = cal_meal_time(df_insulin, df_cgm)\n",
    "gt_df = cal_gt(df_insulin,x1_len)\n",
    "\n",
    "feature_matrix = np.vstack((x1))\n",
    "\n",
    "df = StandardScaler().fit_transform(feature_matrix)\n",
    "number_clusters = 6\n",
    "km = KMeans(\n",
    "    n_clusters=number_clusters, random_state=0).fit(np.array(df))\n",
    "######################################################\n",
    "#### ground truth labels #############################\n",
    "######################################################\n",
    "ground_truth_bins = gt_df[\"bins\"]\n",
    "#print(ground_truth_bins)\n",
    "true_labels = np.asarray(ground_truth_bins).flatten()\n",
    "for i in range(len(true_labels)):\n",
    "    if math.isnan(true_labels[i]):\n",
    "        true_labels[i] = 1\n",
    "\n",
    "######################################################\n",
    "########### kmean labels #############################\n",
    "######################################################\n",
    "kmeans_labels = km.labels_\n",
    "for ii in range(len(kmeans_labels)):\n",
    "    kmeans_labels[ii] = kmeans_labels[ii] + 1\n",
    "\n",
    "######################################################\n",
    "############ calculate SSE for kmean #################\n",
    "######################################################\n",
    "total, bin_1, bin_2, bin_3, bin_4, bin_5, bin_6 = get_bins(kmeans_labels,true_labels)\n",
    "\n",
    "kmean_SSE = (calculateSSE(bin_1) * len(bin_1) + calculateSSE(bin_2) * len(bin_2) + calculateSSE(bin_3) * len(bin_3) + calculateSSE(bin_4) * len(bin_4) + calculateSSE(bin_5) * len(bin_5) + calculateSSE(bin_6) * len(bin_6)) / (total)\n",
    "\n",
    "#kmean_SSE = km.inertia_ /total\n",
    "#### calculate entropy and purity #####\n",
    "#print(\"true labels ####\", true_labels)\n",
    "km_contingency = contingency_matrix(true_labels, kmeans_labels)\n",
    "entropy, purity = [], []\n",
    "for cluster in km_contingency:\n",
    "    cluster = cluster / float(cluster.sum())\n",
    "    #print(\"cluster #####\", cluster)\n",
    "    e = 0\n",
    "    for x in cluster :\n",
    "        if x !=0 :\n",
    "            e = (cluster * [log(x, 2)]).sum()\n",
    "        #else:\n",
    "        #    e = cluster.sum()\n",
    "    p = cluster.max()\n",
    "    entropy += [e]\n",
    "    purity += [p]\n",
    "counts = np.array([c.sum() for c in km_contingency])\n",
    "coeffs = counts / float(counts.sum())\n",
    "kmean_entropy = (coeffs * entropy).sum()\n",
    "kmean_purity = (coeffs * purity).sum()\n",
    "#print('kmean entropy: ', kmean_entropy)\n",
    "#print('kmean purity: ', kmean_purity)\n",
    "\n",
    "######################################################\n",
    "############ Plot DB Scan ############################\n",
    "######################################################\n",
    "feature_new = []\n",
    "for i in feature_matrix:\n",
    "    feature_new.append(i[1])\n",
    "\n",
    "feature_new = np.array(feature_new)\n",
    "feature_new = feature_new.reshape(-1, 1)\n",
    "\n",
    "X = StandardScaler().fit_transform(feature_new)\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=10).fit(X)\n",
    "#X = StandardScaler().fit_transform(feature_new)\n",
    "#dbscan = DBSCAN(eps=9, min_samples=5).fit(feature_new)\n",
    "dbs_labels = dbscan.labels_\n",
    "print(dbs_labels)\n",
    "\n",
    "######################################################\n",
    "############ calculate SSE for kmean #################\n",
    "######################################################\n",
    "total, bin_1, bin_2, bin_3, bin_4, bin_5, bin_6 = get_bins(dbs_labels,true_labels)\n",
    "\n",
    "dbs_SSE = (calculateSSE(bin_1) * len(bin_1) + calculateSSE(bin_2) * len(bin_2) + calculateSSE(bin_3) * len(bin_3) + calculateSSE(bin_4) * len(bin_4) + calculateSSE(bin_5) * len(bin_5) + calculateSSE(bin_6) * len(bin_6)) / (total)\n",
    "\n",
    "#print(\"dbs SSE #######\", dbs_SSE)\n",
    "\n",
    "#### calculate entropy and purity #####\n",
    "dbs_contingency = contingency_matrix(true_labels, dbs_labels)\n",
    "entropy, purity = [], []\n",
    "for cluster in dbs_contingency:\n",
    "    cluster = cluster / float(cluster.sum())\n",
    "    #print(\"cluster #####\", cluster)\n",
    "    e = 0\n",
    "    for x in cluster :\n",
    "        if x !=0 :\n",
    "            e = (cluster * [log(x, 2)]).sum()\n",
    "        #else:\n",
    "        #    e = cluster.sum()\n",
    "    p = cluster.max()\n",
    "    entropy += [e]\n",
    "    purity += [p]\n",
    "counts = np.array([c.sum() for c in km_contingency])\n",
    "coeffs = counts / float(counts.sum())\n",
    "dbs_entropy = (coeffs * entropy).sum()\n",
    "dbs_purity = (coeffs * purity).sum()\n",
    "#print('dbs entropy: ', dbs_entropy)\n",
    "#print('dbs purity: ', dbs_purity)\n",
    "\n",
    "result = []\n",
    "result.append([kmean_SSE, dbs_SSE, kmean_entropy, dbs_entropy, kmean_purity, dbs_purity])\n",
    "result = np.array(result)\n",
    "np.savetxt('./Result.csv', result, fmt=\"%f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
